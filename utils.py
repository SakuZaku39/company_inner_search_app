"""
Streamlit Cloudç”¨ã®è»½é‡ç‰ˆ utils.py
langchain_experimental ã‚’ä½¿ã‚ãšã«å¾“æ¥­å“¡æ¤œç´¢ã‚’å®Ÿè£…
"""

from __future__ import annotations

############################################################
# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
############################################################
import os
import pandas as pd
import re
from dotenv import load_dotenv
import streamlit as st
from langchain.schema import HumanMessage, SystemMessage, AIMessage
from langchain_openai import ChatOpenAI
import constants as ct
from typing import Optional
from tabulate import tabulate

############################################################
# è¨­å®šé–¢é€£
############################################################
# ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã§å®šç¾©ã—ãŸç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

############################################################
# å¾“æ¥­å“¡æ¤œç´¢é–¢æ•°ï¼ˆè»½é‡ç‰ˆï¼‰
############################################################

def detect_employee_query(query: str) -> bool:
    """å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹ã‚¯ã‚¨ãƒªã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    employee_keywords = [
        "å¾“æ¥­å“¡", "ç¤¾å“¡", "ã‚¹ã‚¿ãƒƒãƒ•", "äººäº‹", "å–¶æ¥­", "é–‹ç™º", "çµŒç†", "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°",
        "éƒ¨é•·", "èª²é•·", "ä¸»ä»»", "ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼", "ãƒªãƒ¼ãƒ€ãƒ¼", "ãƒãƒ¼ãƒ•",
        "äººæ•°", "ä¸€è¦§", "åå‰", "æ°å", "è·ä½", "å½¹è·", "éƒ¨ç½²"
    ]
    return any(keyword in query for keyword in employee_keywords)

def simple_employee_search(query: str) -> dict:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªå¾“æ¥­å“¡æ¤œç´¢ï¼ˆPandas Agentã‚’ä½¿ã‚ãªã„ç‰ˆï¼‰"""
    try:
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        csv_path = "./data/ç¤¾å“¡ã«ã¤ã„ã¦/ç¤¾å“¡åç°¿.csv"
        if not os.path.exists(csv_path):
            return {
                "answer": "å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚",
                "success": False
            }
        
        df = pd.read_csv(csv_path, encoding='utf-8')
        
        # ã‚¯ã‚¨ãƒªã‹ã‚‰éƒ¨ç½²ã‚’æŠ½å‡º
        departments = ["äººäº‹éƒ¨", "å–¶æ¥­éƒ¨", "é–‹ç™ºéƒ¨", "çµŒç†éƒ¨", "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°éƒ¨"]
        found_dept = None
        for dept in departments:
            if dept.replace("éƒ¨", "") in query or dept in query:
                found_dept = dept
                break
        
        # å½¹è·ã‚’æŠ½å‡º
        positions = ["éƒ¨é•·", "èª²é•·", "ä¸»ä»»", "ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼", "ãƒªãƒ¼ãƒ€ãƒ¼", "ãƒãƒ¼ãƒ•", "ã‚¹ã‚¿ãƒƒãƒ•"]
        found_position = None
        for pos in positions:
            if pos in query:
                found_position = pos
                break
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_df = df.copy()
        
        if found_dept:
            filtered_df = filtered_df[filtered_df['éƒ¨ç½²'] == found_dept]
        
        if found_position:
            if found_position == "ã‚¹ã‚¿ãƒƒãƒ•":
                # ã‚¹ã‚¿ãƒƒãƒ•ã®å ´åˆã¯ç®¡ç†è·ä»¥å¤–
                management_positions = ["éƒ¨é•·", "èª²é•·", "ä¸»ä»»", "ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼", "ãƒªãƒ¼ãƒ€ãƒ¼", "ãƒãƒ¼ãƒ•"]
                filtered_df = filtered_df[~filtered_df['å½¹è·'].isin(management_positions)]
            else:
                filtered_df = filtered_df[filtered_df['å½¹è·'] == found_position]
        
        if filtered_df.empty:
            # è©²å½“ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if found_dept:
                dept_df = df[df['éƒ¨ç½²'] == found_dept]
                if not dept_df.empty:
                    table = tabulate(dept_df, headers='keys', tablefmt='pipe', showindex=False)
                    return {
                        "answer": f"**{found_dept}ã®å¾“æ¥­å“¡ä¸€è¦§**\n\n{table}\n\nâ€» ç‰¹å®šã®å½¹è·ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€éƒ¨ç½²å…¨ä½“ã®æƒ…å ±ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚",
                        "success": True
                    }
            
            return {
                "answer": "è©²å½“ã™ã‚‹å¾“æ¥­å“¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¤œç´¢æ¡ä»¶ã‚’å¤‰æ›´ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚",
                "success": False
            }
        
        # çµæœã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§æ•´å½¢
        table = tabulate(filtered_df, headers='keys', tablefmt='pipe', showindex=False)
        
        result_text = f"**æ¤œç´¢çµæœ: {len(filtered_df)}ä»¶**\n\n{table}"
        
        if found_dept:
            result_text += f"\n\nğŸ“Š **{found_dept}** ã®æ¤œç´¢çµæœ"
        if found_position:
            result_text += f"\nğŸ·ï¸ **{found_position}** ã§çµã‚Šè¾¼ã¿"
            
        return {
            "answer": result_text,
            "success": True
        }
        
    except Exception as e:
        return {
            "answer": f"å¾“æ¥­å“¡æ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "success": False
        }

def query_employee_data(query: str) -> dict:
    """å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ã‚¯ã‚¨ãƒªã®ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    return simple_employee_search(query)

############################################################
# æ—¢å­˜ã®é–¢æ•°ç¾¤ï¼ˆå¤‰æ›´ãªã—ï¼‰
############################################################

def get_source_icon(source):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ä¸€ç·’ã«è¡¨ç¤ºã™ã‚‹ã‚¢ã‚¤ã‚³ãƒ³ã®ç¨®é¡ã‚’å–å¾—"""
    if source.startswith("http"):
        icon = ct.LINK_SOURCE_ICON
    else:
        icon = ct.DOC_SOURCE_ICON
    return icon

def build_error_message(error_message):
    """ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ•´å½¢ã—ã¦è¿”ã™"""
    return f"{ct.ERROR_ICON} **ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ**\n\n{error_message}\n\n{ct.COMMON_ERROR_MESSAGE}"

def get_llm_response(chat_message):
    """LLMã‹ã‚‰å›ç­”ã‚’ç”Ÿæˆã™ã‚‹"""
    try:
        # å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹ã‚¯ã‚¨ãƒªã‹ã©ã†ã‹ã‚’åˆ¤å®š
        if detect_employee_query(chat_message):
            # å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
            employee_response = query_employee_data(chat_message)
            # ä¼šè©±å±¥æ­´ã«è¿½åŠ ï¼ˆStreamlitã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã®ã¿ï¼‰
            try:
                if hasattr(st, 'session_state') and hasattr(st.session_state, 'chat_history'):
                    st.session_state.chat_history.extend([
                        HumanMessage(content=chat_message), 
                        employee_response["answer"]
                    ])
            except Exception:
                pass
            return employee_response
        
        # è»½é‡ç‰ˆLLMå‡¦ç†ï¼ˆRAGæ©Ÿèƒ½ãªã—ï¼‰
        try:
            llm = ChatOpenAI(model_name=ct.MODEL, temperature=ct.TEMPERATURE)

            # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠ
            try:
                current_mode = st.session_state.mode if hasattr(st, 'session_state') and hasattr(st.session_state, 'mode') else ct.ANSWER_MODE_2
            except Exception:
                current_mode = ct.ANSWER_MODE_2

            if current_mode == ct.ANSWER_MODE_1:
                system_prompt = ct.SYSTEM_PROMPT_DOC_SEARCH
            else:
                system_prompt = ct.SYSTEM_PROMPT_INQUIRY
            
            # LangChainäº’æ›ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½¿ç”¨
            from langchain.schema import SystemMessage, HumanMessage as LCHumanMessage
            
            messages = [SystemMessage(content=system_prompt)]
            
            # ä¼šè©±å±¥æ­´ã‚’å–å¾—
            try:
                chat_history = st.session_state.chat_history if hasattr(st, 'session_state') and hasattr(st.session_state, 'chat_history') else []
            except Exception:
                chat_history = []

            # éå»ã®ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆæœ€æ–°ã®4ã¤ã¾ã§ï¼‰
            if chat_history:
                for i, msg in enumerate(chat_history[-8:]):  # æœ€æ–°8ä»¶ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼4+ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ4ï¼‰
                    if i % 2 == 0:  # å¶æ•°ç•ªç›®ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                        content = str(msg.content) if hasattr(msg, 'content') else str(msg)
                        messages.append(LCHumanMessage(content=content))
                    else:  # å¥‡æ•°ç•ªç›®ã¯ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                        from langchain.schema import AIMessage
                        content = str(msg)
                        messages.append(AIMessage(content=content))
            
            # ç¾åœ¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            messages.append(LCHumanMessage(content=chat_message))

            # LLMå¿œç­”å–å¾—
            response = llm.invoke(messages)

            # LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¼šè©±å±¥æ­´ã«è¿½åŠ 
            try:
                if hasattr(st, 'session_state') and hasattr(st.session_state, 'chat_history'):
                    st.session_state.chat_history.extend([HumanMessage(content=chat_message), response.content])
            except Exception:
                pass

            return {
                "answer": response.content,
                "context": []
            }
            
        except Exception as llm_error:
            # LLMå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã®è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
            error_details = str(llm_error)
            
            # ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã€ã‚ˆã‚Šå…·ä½“çš„ãªå¯¾å‡¦æ³•ã‚’æç¤º
            if "rate limit" in error_details.lower():
                fallback_message = "âš ï¸ OpenAI APIã®åˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            elif "authentication" in error_details.lower() or "api key" in error_details.lower():
                fallback_message = "âš ï¸ OpenAI APIã‚­ãƒ¼ã®èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"
            elif "connection" in error_details.lower() or "network" in error_details.lower():
                fallback_message = "âš ï¸ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            else:
                fallback_message = f"âš ï¸ AIå¿œç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n\nè©³ç´°: {error_details}\n\nå¾“æ¥­å“¡æƒ…å ±ã®æ¤œç´¢ã¯å¼•ãç¶šãåˆ©ç”¨å¯èƒ½ã§ã™ã€‚"
            
            return {
                "answer": fallback_message,
                "context": []
            }

    except Exception as e:
        error_message = f"LLMå¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        return {"answer": build_error_message(error_message)}
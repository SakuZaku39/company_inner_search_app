"""
Streamlit Cloudç”¨ã®è»½é‡ç‰ˆ utils.py
langchain_experimental ã‚’ä½¿ã‚ãšã«å¾“æ¥­å“¡æ¤œç´¢ã‚’å®Ÿè£…
"""

from __future__ import annotations

############################################################
# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
############################################################
import os
import pandas as pd
import re
from dotenv import load_dotenv
import streamlit as st
from langchain.schema import HumanMessage, SystemMessage, AIMessage
from langchain_openai import ChatOpenAI
import constants as ct
from typing import Optional
from tabulate import tabulate

############################################################
# è¨­å®šé–¢é€£
############################################################
# ã€Œ.envã€ãƒ•ã‚¡ã‚¤ãƒ«ã§å®šç¾©ã—ãŸç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

############################################################
# çœŸã®RAGçµ±åˆé–¢æ•°
############################################################

def create_csv_documents():
    """CSVãƒ‡ãƒ¼ã‚¿ã‚’RAGç”¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå½¢å¼ã«å¤‰æ›"""
    from langchain.schema import Document
    
    try:
        csv_path = "./data/ç¤¾å“¡ã«ã¤ã„ã¦/ç¤¾å“¡åç°¿.csv"
        if not os.path.exists(csv_path):
            return []
        
        df = pd.read_csv(csv_path, encoding='utf-8')
        documents = []
        
        # å„å¾“æ¥­å“¡ã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–
        for index, row in df.iterrows():
            content = f"""å¾“æ¥­å“¡æƒ…å ±:
æ°å: {row['æ°åï¼ˆãƒ•ãƒ«ãƒãƒ¼ãƒ ï¼‰']}
éƒ¨ç½²: {row['éƒ¨ç½²']}
å½¹è·: {row['å½¹è·']}
å¾“æ¥­å“¡åŒºåˆ†: {row['å¾“æ¥­å“¡åŒºåˆ†']}
ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ: {row['ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ']}
ä¿æœ‰è³‡æ ¼: {row['ä¿æœ‰è³‡æ ¼']}
å¹´é½¢: {row['å¹´é½¢']}æ­³
å…¥ç¤¾æ—¥: {row['å…¥ç¤¾æ—¥']}"""
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«éƒ¨ç½²æƒ…å ±ãªã©ã‚’å«ã‚ã‚‹
            metadata = {
                "source": "ç¤¾å“¡åç°¿.csv",
                "type": "employee_data",
                "department": row['éƒ¨ç½²'],
                "name": row['æ°åï¼ˆãƒ•ãƒ«ãƒãƒ¼ãƒ ï¼‰'],
                "role": row['å½¹è·']
            }
            
            documents.append(Document(page_content=content, metadata=metadata))
        
        # éƒ¨ç½²åˆ¥ã‚µãƒãƒªãƒ¼ã‚‚ä½œæˆ
        for dept in df['éƒ¨ç½²'].unique():
            dept_df = df[df['éƒ¨ç½²'] == dept]
            summary_content = f"""{dept}ã®æ¦‚è¦:
æ‰€å±äººæ•°: {len(dept_df)}å
ä¸»ãªå½¹è·: {', '.join(dept_df['å½¹è·'].unique())}
å¾“æ¥­å“¡åŒºåˆ†: {', '.join(dept_df['å¾“æ¥­å“¡åŒºåˆ†'].unique())}
            # ä»£è¡¨çš„ãªã‚¹ã‚­ãƒ«: {', '.join(list(set([skill for skills in dept_df['ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆ'].dropna().str.split(', ') for skill in skills]))[:10])}"""
            
            metadata = {
                "source": f"{dept}_æ¦‚è¦",
                "type": "department_summary", 
                "department": dept
            }
            
            documents.append(Document(page_content=summary_content, metadata=metadata))
        
        return documents
        
    except Exception as e:
        print(f"CSVæ–‡æ›¸åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def format_search_results(retrieved_docs, query):
    """æ¤œç´¢çµæœã‚’å‹•çš„ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ - ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ãƒšãƒ¼ã‚¸æ•°ã‚’å«ã‚€è¡¨ç¤º"""
    if not retrieved_docs:
        return "é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    # å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    employee_docs = [doc for doc in retrieved_docs if doc.metadata.get("type") == "employee_data"]
    dept_summary_docs = [doc for doc in retrieved_docs if doc.metadata.get("type") == "department_summary"]
    other_docs = [doc for doc in retrieved_docs if doc.metadata.get("type") not in ["employee_data", "department_summary"]]
    
    result = ""
    
    # å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§è¡¨ç¤º
    if employee_docs:
        result += "**é–¢é€£ã™ã‚‹å¾“æ¥­å“¡æƒ…å ±:**\n\n"
        
        # ç°¡æ½”ãªãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼
        table_data = []
        for doc in employee_docs[:10]:  # æœ€å¤§10ä»¶
            lines = doc.page_content.split('\n')
            name = lines[1].replace('æ°å: ', '') if len(lines) > 1 else "ä¸æ˜"
            dept = lines[2].replace('éƒ¨ç½²: ', '') if len(lines) > 2 else "ä¸æ˜"
            role = lines[3].replace('å½¹è·: ', '') if len(lines) > 3 else "ä¸æ˜"
            table_data.append(f"| {name} | {dept} | {role} |")
        
        if table_data:
            result += "| æ°å | éƒ¨ç½² | å½¹è· |\n|------|------|------|\n"
            result += "\n".join(table_data) + "\n\n"
        
        # å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ã®ã‚½ãƒ¼ã‚¹è¡¨ç¤º
        result += "**ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:**\n"
        result += f"ğŸ“Š data/ç¤¾å“¡ã«ã¤ã„ã¦/ç¤¾å“¡åç°¿.csv\n\n"
    
    # éƒ¨ç½²æ¦‚è¦ãŒã‚ã‚‹å ´åˆ
    if dept_summary_docs:
        result += "**éƒ¨ç½²æ¦‚è¦:**\n\n"
        for doc in dept_summary_docs:
            result += doc.page_content + "\n\n"
    
    # ä»–ã®æ–‡æ›¸ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ± - ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ãƒšãƒ¼ã‚¸æ•°ã‚’è¡¨ç¤º
    if other_docs:
        result += "**å…¥åŠ›å†…å®¹ã«é–¢ã™ã‚‹æƒ…å ±ã¯ã€ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™:**\n\n"
        
        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨
        displayed_sources = set()
        
        for doc in other_docs[:5]:  # æœ€å¤§5ä»¶
            source = doc.metadata.get('source', 'ä¸æ˜ãªã‚½ãƒ¼ã‚¹')
            page = doc.metadata.get('page')
            
            # é‡è¤‡ã‚’é¿ã‘ã‚‹
            source_key = f"{source}_{page}" if page else source
            if source_key in displayed_sources:
                continue
            displayed_sources.add(source_key)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¡¨ç¤º
            if source.endswith('.pdf') and page:
                file_display = f"ğŸ“„ {source} (ãƒšãƒ¼ã‚¸No.{page})"
            else:
                file_display = f"ğŸ“„ {source}"
            
            result += f"{file_display}\n"
        
        result += "\n**ãã®ä»–ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚ã‚Šã‹ã®å€™è£œã‚’æç¤ºã—ã¾ã™:**\n\n"
    
    return result

# å¾“æ¥ã®å€‹åˆ¥å¾“æ¥­å“¡æ¤œç´¢é–¢æ•°ã¯å‰Šé™¤
# å…¨ã¦RAGã§çµ±ä¸€å‡¦ç†ã™ã‚‹ãŸã‚ä¸è¦

############################################################
# æ—¢å­˜ã®é–¢æ•°ç¾¤ï¼ˆå¤‰æ›´ãªã—ï¼‰
############################################################

def get_source_icon(source):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ä¸€ç·’ã«è¡¨ç¤ºã™ã‚‹ã‚¢ã‚¤ã‚³ãƒ³ã®ç¨®é¡ã‚’å–å¾—"""
    if source.startswith("http"):
        icon = ct.LINK_SOURCE_ICON
    else:
        icon = ct.DOC_SOURCE_ICON
    return icon

def format_pdf_reference(file_path, page_number=None):
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒšãƒ¼ã‚¸æ•°ã‚’å«ã‚€å‚ç…§å½¢å¼ã‚’ç”Ÿæˆ"""
    if file_path.endswith('.pdf') and page_number:
        return f"{file_path} (ãƒšãƒ¼ã‚¸No.{page_number})"
    else:
        return file_path

def build_error_message(error_message):
    """ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ•´å½¢ã—ã¦è¿”ã™"""
    return f"{ct.ERROR_ICON} **ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ**\n\n{error_message}\n\n{ct.COMMON_ERROR_MESSAGE}"

def get_llm_response(chat_message):
    """LLMã‹ã‚‰å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆçœŸã®RAGã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰"""
    try:
        # çµ±ä¸€RAGã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: å…¨ã¦ã®ã‚¯ã‚¨ãƒªã‚’åŒã˜æ–¹æ³•ã§å‡¦ç†
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ¤å®šã¯å»ƒæ­¢ã—ã€RAGã®è‡ªç„¶ãªæ¤œç´¢ã«ä»»ã›ã‚‹
        
        # çœŸã®RAGå‡¦ç†: å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆæ¤œç´¢
        llm = ChatOpenAI(model_name=ct.MODEL, temperature=ct.TEMPERATURE)
        
        # RAGãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã®å–å¾—ï¼ˆç·Šæ€¥ä¿®æ­£: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¼·åŒ–ï¼‰
        retriever = None
        try:
            # Streamlitç’°å¢ƒã§ã®å–å¾—ã‚’è©¦è¡Œ
            if hasattr(st, 'session_state') and hasattr(st.session_state, 'retriever'):
                retriever = st.session_state.retriever
            
            # retrieverãŒNoneã®å ´åˆã€ç·Šæ€¥åˆæœŸåŒ–ã‚’è©¦è¡Œ
            if retriever is None:
                print("âš ï¸ retriever ãŒ None ã§ã™ã€‚ç·Šæ€¥åˆæœŸåŒ–ã‚’è©¦è¡Œ...")
                from initialize_ultra_lite import initialize_retriever
                retriever = initialize_retriever()
                
                # åˆæœŸåŒ–æˆåŠŸæ™‚ã¯session_stateã«ä¿å­˜
                if retriever and hasattr(st, 'session_state'):
                    st.session_state.retriever = retriever
                    print("âœ… retriever ç·Šæ€¥åˆæœŸåŒ–æˆåŠŸ")
                    
        except Exception as e:
            print(f"Retrieverå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            retriever = None
        
        if retriever is None:
            # ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            try:
                chat_history = st.session_state.chat_history if hasattr(st, 'session_state') and hasattr(st.session_state, 'chat_history') else []
            except Exception:
                chat_history = []
            
            messages = [
                SystemMessage(content="ã‚ãªãŸã¯ç¤¾å†…æƒ…å ±ã«è©³ã—ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚è³ªå•ã«ä¸å¯§ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"),
                HumanMessage(content=chat_message)
            ]
            
            response = llm.invoke(messages)
            
            try:
                if hasattr(st, 'session_state') and hasattr(st.session_state, 'chat_history'):
                    st.session_state.chat_history.extend([HumanMessage(content=chat_message), response.content])
            except Exception:
                pass
            
            return {
                "answer": response.content + "\n\nâš ï¸ **ç·Šæ€¥ãƒ¢ãƒ¼ãƒ‰**: æ–‡æ›¸æ¤œç´¢æ©Ÿèƒ½ãŒä¸€æ™‚çš„ã«åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚",
                "context": []
            }
        
        # RAGæ¤œç´¢å®Ÿè¡Œ
        try:
            retrieved_docs = retriever.invoke(chat_message)
            
            # çµæœã®å‹•çš„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            formatted_results = format_search_results(retrieved_docs, chat_message)
            
            # LLMã«ã‚ˆã‚‹çµ±åˆå›ç­”ç”Ÿæˆ
            context_text = "\n\n".join([doc.page_content for doc in retrieved_docs[:5]])  # ä¸Šä½5ä»¶
            
            system_prompt = """ã‚ãªãŸã¯ç¤¾å†…æƒ…å ±æ¤œç´¢ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
æä¾›ã•ã‚ŒãŸæƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ­£ç¢ºã§æœ‰ç”¨ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
å¾“æ¥­å“¡æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¡¨å½¢å¼ã§æ•´ç†ã—ã€æ–‡æ›¸æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è¦ç‚¹ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"""
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"è³ªå•: {chat_message}\n\næ¤œç´¢çµæœ:\n{context_text}\n\nä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚")
            ]
            
            response = llm.invoke(messages)
            
            # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
            try:
                if hasattr(st, 'session_state') and hasattr(st.session_state, 'chat_history'):
                    st.session_state.chat_history.extend([HumanMessage(content=chat_message), response.content])
            except Exception:
                pass
            
            return {
                "answer": response.content,
                "context": retrieved_docs,
                "mode": ct.ANSWER_MODE_1 if hasattr(st, 'session_state') and st.session_state.get("mode") == ct.ANSWER_MODE_1 else ct.ANSWER_MODE_2
            }
            
        except Exception as rag_error:
            # RAGå‡¦ç†ã‚¨ãƒ©ãƒ¼ã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            fallback_message = f"âš ï¸ æ¤œç´¢å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(rag_error)}\n\nåŸºæœ¬çš„ãªå¿œç­”æ©Ÿèƒ½ã§å¯¾å¿œã—ã¾ã™ã€‚"
            
            messages = [
                SystemMessage(content="ã‚ãªãŸã¯ç¤¾å†…æƒ…å ±ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
                HumanMessage(content=chat_message)
            ]
            
            try:
                response = llm.invoke(messages)
                return {
                    "answer": response.content + f"\n\n{fallback_message}",
                    "context": []
                }
            except Exception:
                return {
                    "answer": fallback_message,
                    "context": []
                }

    except Exception as e:
        error_message = f"LLMå¿œç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        return {"answer": build_error_message(error_message)}